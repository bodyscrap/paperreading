# Computing the Stereo Matching Cost with a Convolutional Neural Network
[paper](https://arxiv.org/abs/1409.4326)
[code](https://github.com/leduoyang/depth_estimation_MCCNN)


## Abstruct
平行化された画像ペアから奥行き情報を抽出する方法を提案する。
畳み込みニューラルネットワークを学習し、2つの画像パッチの一致度を予測し、それを用いてステレオマッチングコストを計算する。
このコストは、交差ベースのコスト集計とセミグローバルマッチングによって精緻化され、その後、左右の整合性チェックが行われ、オクルージョン領域の誤差が除去される。
提案ステレオ手法は、KITTIステレオデータセットにおいて2.61 %のエラー率を達成し、現在(2014年8月)、このデータセットにおいてトップの性能を持つ手法である。

## 1. Introduction
異なる水平位置のカメラから撮影された2つの画像が与えられたとき、左の画像の各画素の視差$d$を計算することを目的とする。 
視差とは、左右の画像における物体の水平方向の位置の差のことで、左の画像の位置 $(x,y)$ にある物体は、右の画像の位置 $(x - d, y)$に見えることになる。
ある物体の視差 $d$ がわかれば、次式を用いて、その物体の奥行き $z$(つまり、物体からカメラまでの距離)を計算することができる:

$$
z=\frac{fB}{d}, \tag{1}
$$

ここで$f$はカメラの焦点距離、$B$はカメラ中心間の距離である。
この問題はステレオ再構成の下位問題であり、1つ以上の画像から3次元形状を抽出することが目的である。
Scharstein and Szeliski [14]の分類法によれば、典型的なステレオアルゴリズムは4つのステップから構成される： 
(1) マッチング・コスト計算 
(2) コスト集約、
(3) 最適化 
(4) 視差の精緻化
Hirschmuller and Scharstein [5]に従い、(1)と(2)のステップをマッチングコスト計算、(3)と(4)のステップをステレオ手法と呼ぶ。
我々は、真の視差が既知である(例えばLIDARによって得られた)小さな画像パッチのペアで畳み込みニューラルネットワーク[9]を訓練することを提案する。
ネットワークの出力は、一対のパッチ間のマッチングコストを初期化するために使用される。
マッチング・コストは、クロス・ベースのコスト集約を用いて、画像輝度が類似する隣接ピクセル間で結合される。
滑らかさの制約はセミグローバルマッチングによって強制され、左右の一貫性チェックはオクルージョン領域のエラーを検出して除去するために用いられる。
サブピクセル強調を行い、メディアンフィルターとバイラテラルフィルターを適用して、最終的な視差マップを得る。
Figure 1は我々の手法の入力と出力を示している。

本稿の貢献は以下の2点である：
- 畳み込みニューラルネットワークを用いてステレオ・マッチング・コストを計算する方法を説明
- KITTIステレオデータセットにおいて、誤差2.61 %を達成し、従来の最高結果2.83 %より改善。

![Figure1](images/Figure1.png)
Figure 1. 入力は左右のカメラからの一対の画像である。
2つの入力画像は、主に物体の水平方向の位置が異なる。
カメラに近い物体は、遠い物体よりも視差が大きいことに注意。
出力は、右図に示すdenseなの視差マップである。
暖かい色は、視差の大きな値(深度としては小さな値)を表す。

## 2. Related work
大規模なステレオデータセット[2, 13]が導入される以前は、モデルのパラメータを学習するためにground-truth情報を使用するステレオ・アルゴリズム は比較的少なかった。
ステレオ・アルゴリズムの一般的な概要については[14]を参照。
KongとTao[6]は、距離の二乗和を使用して初期マッチング・コストを計算した。
彼らは、初期視差が正しい、前景オブジェクトが大きくなったため初期視差が正しくない、その他の理由で初期視差が正しくない、という3つのクラスの確率分布を予測するモデルを学習した。
予測された確率は、初期マッチング・コストの調整に用いられた。
KongとTao [7]は後に、異なるサイズと中心を持つウィンドウで正規化相互相関を計算することで得られた予測を組み合わせることで、彼らの研究を拡張している。
Perisら[12]は、AD-Census[11]を用いてマッチング・コストを初期化し、多クラス線形判別分析を用いて、計算されたマッチング・コストから最終的な視差へのマッピングを学習した。
ground truth データはまた、グラフィカル・モデルのパラメータを学習するためにも使用された。
ZhangとSeitz[22]は、マルコフランダム・フィールドのハイパーパラメータの最適値を推定するために、別の最適化アルゴリズムを使用した。
ScharsteinとPal[13]は、30組のステレオ・ペアからなる新しいデータセットを構築し、条件付きランダム・フィールドのパラメータ学習に利用した。
LiとHuttenlocher[10]は、ノンパラメトリックなコスト関数を持つ条件付きランダムフィールドモデルを提示し、構造化サポートベクターマシンを用いてモデルパラメータを学習した。 
最近の研究[3, 15]は、計算されたマッチング・コストの信頼度を推定することに焦点を当てている。
Haeuslerら[3]は、ランダムフォレスト分類器を用いて、複数の信頼度尺度を組み合わせている。
同様に、Spyropoulosら[15]は、マッチング・コストの信頼度を予測するためにランダム・フォレスト分類器を学習し、ステレオ法の誤差を減少させるために、マルコフ・ランダム・フィールドのソフト制約として予測値を使用した。

## 3. Computing the matching cost
典型的なステレオ・アルゴリズムでは、まず、すべての視差 $\mathbf{d}$ について、各位置 $\mathbf{p}$ でのマッチング・コスト $C( \mathbf{p},\mathbf{d})$ を計算する。
簡単な例として、差の絶対値の和がある：

$$
C_{AD}(\mathbf{p}, d) = \sum_{\mathbf{q}\in \mathit{N}_{\mathbf{p}}} | I^L(\mathbf{q}) - I^R(\mathbf{qd})|, \tag{2}
$$

ここで、$I^L(\mathbf{p})$ と $I^R(\mathbf{p})$ は左右の画像の位置 $\mathbf{p}$ における画像の輝度であり、$\mathit{N}_{\mathbf{p}}$ は $\mathbf{p}$ を中心とする固定矩形窓内の位置の集合である。 
太字の小文字 $(\mathbf{p, q, r})$ で実数の組を表す。
小文字の $\mathbf{d}$ の付加は以下の意味を持つ：$\mathbf{p} = (x,y)$ ならば、$\mathbf{pd} = (x - d, y)$ 。
式(2)は、位置 $\mathbf{p}$ を中心とする左画像からのパッチと、位置 $\mathbf{pd}$ を中心とする右画像からのパッチのマッチングに関連するコストを測定すると解釈できる。
良いマッチングと悪いマッチングの例は、KITTI [2]やMiddlebury [14]などの一般に利用可能なデータセットから得られるので、教師あり学習アプローチによってマッチング問題を解くことができる。
視覚問題への畳み込みニューラルネットワークの応用の成功[8]に触発され、我々は2つの小さな画像パッチがどの程度一致するかを評価するために畳み込みニューラルネットワークを用いた。

### 3.1. Creating the dataset
訓練例は2つのパッチから構成される。1つは左の画像から、もう1つは右の画像から：
$$
\left< \mathit{P}^L_{9\times9}(\mathbf{p}), \mathit{P}^R_{9\times9}(\mathbf{q})\right>, \tag{3}
$$

ここで、 $\mathit{P}^L_{9\times9}(\mathbf{p})$ は左画像からの $9\times9$ のパッチを表し、 $\mathbf{p} = (x,y)$ を中心とする。
真の視差 $d$ が既知の各位置について、負と正の例を1つずつ抽出する。
負の例は、右のパッチの中心 $\mathbf{q}$ を次式の様にする

$$
\mathbf{q} = (x - d + o_{neg}, y), \tag{4}
$$

ここで、 $o_{neg}$ はマッチを破壊するオフセットで、集合 ${-N_{hi},\dots,N_{lo},N_{lo},\dots, N_{hi}}$ からランダムに選ばれる。
同様に、正例は次のように設定することで導かれる。

$$
\mathbf{q} = (x - d + o_{pos}, y), \tag{5}
$$

ここで、 $o_{pos}$ は集合 $\{-P_{hi},\dots,P_{hi}\}$ からランダムに選ばれる。
ここで、 $o_{pos}$ を0にせず、 $o_{pos}$ に含める理由は、後で用いるステレオ法と関係がある。
特に、ネットワークが良いマッチングだけでなく近いマッチングにも低いマッチング・コストを割り当てるとき、クロス・ベースのコスト集約がより良く機能することがわかった。
$N_{lo},N_{hi},P_{hi}$ と画像パッチのサイズ $n$ はこの手法のハイパーパラメータである。

### 3.2. Network architecture
使用したアーキテクチャを図2に示す。
ネットワークはL1からL8までの8層で構成されている。
第1層は畳み込み型で、他の全ての層は全結合型である。
ネットワークへの入力は2つの $9 \times9$ のグレースケール画像パッチである。
最初の畳み込み層は、サイズ $5 \times 5 \times 1$ の32個のカーネルで構成される。
層L2とL3はそれぞれ200個のニューロンで完全接続される。
L3 の後、2 つの 200 次元ベクトルは 400 次元ベクトルに連結され、300 個のニューロンを持つ 4 つの全結合層、L4 から L7 を通過する。
最後の層であるL8は、出力を2つの実数に投影し、それをソフトマックス関数に通して、(良い一致と悪い一致の)2クラス分布分布を生成する。
左右の画像パッチのネットワークのL1、L2、L3の重みは同値である。
L8を除く各層にはReLUが続く。
我々のアーキテクチャではプーリングは使っていない。
ネットワークには60万近いパラメータが含まれる。
このアーキテクチャーはグレイ画像に適しているが、L1で $5 \times 5 \times 1$ のフィルタを学習する代わりに $5 \times 5 \times 3$ のフィルタを学習することで、RGB画像を扱うように簡単に拡張できる。
ネットワークの最適なハイパーパラメータ(層数、各層のニューロン数、入力パッチのサイズなど)は、データセットによって異なる。
我々がこのアーキテクチャを選んだのは、KITTIステレオデータセットで良好な結果が得られたからである。

![Figure2](images/Figure2.png)
Figure 2. 提案するCNNのアーキテクチャ

## 3.3. Matching cost
マッチングコスト $C_{CNN}( \mathbf{p},d)$ はネットワークの出力から直接計算される：

$$
C_{CNN}(\mathbf{p},d) = f_{neg}(\left< P^L_{9\times9}(\mathbf{p}),P^R_{9\times9}(\mathbf{pd}) \right>), \tag{ 6 }
$$

ここで、$f_{neg}( \left< P^L,P^R \right>)$ は、入力パッチ $P^L$ と $P^R$ に対して実行したときのnetativeクラスのネットワークの出力である。
素直に考えれば、各画像位置 $\mathbf{p}$ と各視差 $d$ に対してフォワードパスを実行しなければならない。
以下の3つの実装により、実行時間を管理可能とした：

1. 層L1、L2、L3の出力は、位置 $\mathbf{p}$ ごとに1回だけ計算すればよく、視差 $d$ ごとに再計算する必要はない。
2. L3 の出力は、$9 \times 9$ の画像パッチではなく、全解像度の画像をネットワークに供給することで、1回のフォワードパスで全ての位置について計算することができる。
そのため、L2層とL3層を畳み込みをもちいて演算する。
L2層は $5 \times 5 \times 32$のフィルタ、L3層は $1\times1\times200$ のフィルタを用い、ともに200個の特徴マップを出力する。
3. 同様に、L4～L8 をサイズ $1 \times 1$ の畳み込みフィルタに置き換えることで、1回のフォワードパスで全ての位置の出力を計算することができる。
残念ながら、各視差に対してフォワードパスを行う必要がある。
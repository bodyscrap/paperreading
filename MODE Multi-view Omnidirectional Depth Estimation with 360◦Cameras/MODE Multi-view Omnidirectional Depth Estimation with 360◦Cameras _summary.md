# [MODE:Multi-view Omnidirectional Depth Estimation with 360° cameras サマリー](https://www.ecva.net//papers/eccv_2022/papers_ECCV/html/6884_ECCV_2022_paper.php)

# 1. どんな論文か？
4つの360°カメラ組のステレオマッチングによる高精度な全方位奥行き推定学習アルゴリズムを提案。また、既存のデータセットに屋外シーンの物が無かったため合成画像による屋外シーンデータセットも提案、学習評価に利用している。また、提案データセットにはレンズが汚染(泥付着や水滴など)されているバージョンの物も含む。

# 2 . 新規性
カッシーニ投影したパノラマ画像ペアを利用することで、2視点間のエピポーラ線を線形(水平線上)に単純化しcost volumeを作成。これにより高精度な視差マップの学習/推定を実現してる。
また、convolutionの際も球面を意識したサンプリングを行うことでパノラマ画像由来の歪みに対応している。  

# 3. 結果
既存の全方位深度推定と比較して、従来の屋内合成画像データセットにおいても、新たに提案した屋内データセットの「Deep360」(通常版/レンズの汚染あり版)においてもstate-of-the-artな性能をマークしている。  

# 4.その他（なぜ通ったか？等）
視差推定の一度平行視点の透視投影画像(=部分視野)のペアにしている手法が多いが、提案手法はカッシーニ投影を用いることでパノラマ画像全体から直接作成している点に新規性がある。
github : https://github.com/nju-ee/MODE-2022  youtube : https://www.youtube.com/watch?v=Fw-KR35UWgQ

---- 関連情報 ----  
cost volume :  
深度推定で最近よく使われている手法。  
[参考1](https://arxiv.org/pdf/1703.04309.pdf)  
[参考2](https://qiita.com/minh33/items/8f3ce0ad64035d994af6)  

参考2の Cost Volumeより  
コストボリュームを形成することにより、ステレオマッチングコストを計算するために、単項のdeep learning特徴を使用します。  
素朴なアプローチでは、左右視野の特徴マップを単純に連結するが、コストボリュームを形成することで、ステレオビジョンの幾何学的知識を保持したままモデルに制約を与えることができる。  
各ステレオ画像に対して、高さ×幅×（最大視差＋1）×特徴量の次元からなるコストボリュームを形成する。
これは、各単項特徴量を、視差レベル毎に反対側のステレオ画像状で対応する単項特徴量と連結し、これらを4次元ボリュームにパッキングすることで実現される。  
特徴量の次元を減少させる内積演算を用いる先行研究[32]とは異なり、この演算により特徴量の次元を保持することができる。  
これにより、特徴の単項演算が可能なコンテキストを取り込む学習が可能となる（セクション3.3）。  
連結された特徴を用いてコストボリュームを形成することで、特徴の減算や距離メトリックを用いるよりも性能が向上することを見出した。  
我々の直感では、特徴量の単項性を維持することで、ネットワークは（距離メトリックではないので）絶対的な表現を学習する機会を得て、これをコストボリュームに引き継ぐことができるというものです。  
これにより、このアーキテクチャはセマンティクスを学習することができる。一方、距離メトリックを用いると、ネットワークは特徴間の相対的な表現しか学習できず、絶対的な特徴表現をコストボリュームに持ち越すことができないという制約がある。

⇒入力の画像(あるいは特徴量マップ)を視差をずらして重ね合わせて、重ね合わせた2つのデータ間の距離(cost)をマップにする。  
1つの視差(disparity)毎に、入力する2つのマップの空間解像度(WxH)と同じマップが出来るので、全体では(WxHxD, Dは視差の種類文)のcost mapが立体(=volume)の形で得られる。  
多分このcost関数は単純にベクトル間距離を使ったり、latent系みたいにcost関数を学習したりするはず。  